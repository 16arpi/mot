<!DOCTYPE html> <html> <head> <title>Projet PPE1-2024</title> <meta charset="utf-8" /> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@1.0.2/css/bulma.min.css"> </head> <body> <section class="section" > <div class="container is-max-desktop" > <div class="content" > <h2 class="title" >Concordancier <code>kr-19</code></h2> <table class="table" > <tr><th>Contexte gauche</th><th>Mot</th><th>Contexte droit</th></tr> <tr> <td>허깅페이스가 새로운 오픈소스 비전 </td> <td>언어</td> <td> 모델 ‘스몰VLM(SmolVLM)’을 26일 출시했다.</td> </tr> <tr> <td>스몰 VLM은 비전(이미지)과 </td> <td>언어</td> <td>(텍스트) 데이터를 함께 처리할 수 있는 모델이다. 이 모델은 이미지를 분석해 설명문을</td> </tr> <tr> <td>허깅페이스가 공개한 스몰 VLM은 20억 개(2B) 파라미터 규모의 소형 비전-</td> <td>언어</td> <td> 모델군으로, 상업적 활용이 가능하며</td> </tr> <tr> <td>멀티모달 AI의 급성장과 함께 대형 비전-</td> <td>언어</td> <td> 모델(Vision-Language Model, VLM)이 잇따라 출시된</td> </tr> </table> </div> </div> </section> </body> </html>
