
허깅페이스가 새로운 오픈소스 비전 언어 모델 ‘스몰VLM(SmolVLM)’을 26일 출시했다.
Hugging Face
CREDIT: T. Schneider / Shutterstock
스몰 VLM은 비전(이미지)과 언어(텍스트) 데이터를 함께 처리할 수 있는 모델이다. 이 모델은 이미지를 분석해 설명문을
생성하고, 이미지와 텍스트를 결합한 질의응답을 수행하며, 시각 데이터에서 특정 정보를 추출해 텍스트로 변환하는 기능을
--
라이브러리에 통합해 제공한다고 밝혔다
허깅페이스가 공개한 스몰 VLM은 20억 개(2B) 파라미터 규모의 소형 비전-언어 모델군으로, 상업적 활용이 가능하며
소규모 로컬 환경에서도 구동할 수 있도록 설계됐다. 특히 이 모델은 AI 학습에 필요한 모든 요소를 투명하게 공개했다는
--
허깅페이스가 최근 생성형 AI 모델의 소형화 트렌드에 발 맞춰 스몰 VLM 모델을 출시했다고 전했다. 허깅페이스는 “올해는
멀티모달 AI의 급성장과 함께 대형 비전-언어 모델(Vision-Language Model, VLM)이 잇따라 출시된
해였다”라며 “초기에는 컴퓨팅 자원을 확장하는 방식이 주를 이 뤘고, 이후 대형 모델로 합성 데이터를 생성해 데이터
